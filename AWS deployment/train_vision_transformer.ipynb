{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.25.42 requires botocore==1.27.42, but you have botocore 1.27.66 which is incompatible.\n",
      "aiobotocore 2.0.1 requires botocore<1.22.9,>=1.22.8, but you have botocore 1.27.66 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install sagemaker transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.108.0\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "print(sagemaker.__version__)\n",
    "\n",
    "role=sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're using the output from a SageMaker Processing job\n",
    "input_path = 's3://sagemaker-eu-central-1-843182712965/sagemaker-scikit-learn-2022-09-03-18-17-21-834/output'\n",
    "\n",
    "train_input_path = '{}/{}'.format(input_path, 'train_data')\n",
    "valid_input_path = '{}/{}'.format(input_path, 'valid_data')\n",
    "test_input_path  = '{}/{}'.format(input_path, 'test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={\n",
    "    'epochs': 3,\n",
    "    'model_name': 'google/vit-base-patch16-224-in21k',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point = 'train_hf_trainer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    role=role,\n",
    "    # Fine-tuning script\n",
    "    entry_point=entry_point,\n",
    "    hyperparameters=hyperparameters,\n",
    "    # Infrastructure\n",
    "    transformers_version='4.17.0',\n",
    "    pytorch_version='1.10.2',\n",
    "    py_version='py38',\n",
    "    instance_type='ml.g4dn.2xlarge',\n",
    "    instance_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.fit(\n",
    "    {'train': train_input_path, \n",
    "     'valid': valid_input_path,\n",
    "     'test': test_input_path,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-central-1-843182712965/huggingface-pytorch-training-2022-09-03-23-36-07-225/output/model.tar.gz'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s $huggingface_estimator.model_data\n",
    "aws s3 cp $1 model-hf.tar.gz\n",
    "tar tvfz model-hf.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace container doesn't support deployment for image classification tasks so we have to use pytorch to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point = 'train_pytorch_lightning.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    role=role,\n",
    "    # Fine-tuning script\n",
    "    entry_point=entry_point,\n",
    "    hyperparameters=hyperparameters,\n",
    "    # Infrastructure\n",
    "    transformers_version='4.17.0',  # Need >= 4.10 because of https://github.com/huggingface/transformers/issues/12904\n",
    "    pytorch_version='1.10.2',\n",
    "    py_version='py38',\n",
    "    instance_type='ml.g4dn.2xlarge',\n",
    "    instance_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_estimator.fit(\n",
    "    {'train': train_input_path, \n",
    "     'valid': valid_input_path,\n",
    "     'test': test_input_path,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-central-1-843182712965/huggingface-pytorch-training-2022-09-10-18-02-18-006/output/model.tar.gz'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-central-1-843182712965/huggingface-pytorch-training-2022-09-04-12-16-25-136/output/model.tar.gz to ./model-pl.tar.gz\n",
      "-rw-r--r-- 0/0      1032158795 2022-09-04 12:25 vit.ckpt\n"
     ]
    }
   ],
   "source": [
    "%%bash -s $huggingface_estimator.model_data\n",
    "aws s3 cp $1 model-pl.tar.gz\n",
    "tar tvfz model-pl.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "rt_predictor = huggingface_estimator.deploy(initial_instance_count=1,\n",
    "                                      instance_type='ml.m5.large', \n",
    "                                      endpoint_name='HuggingFace-ViT',\n",
    "                                      wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process image to pass to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, subprocess, sys, ast, pickle, boto3\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor\n",
    "# Feature Extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "from datasets import Dataset, Features, ClassLabel, Array3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('Validation/Farm/farmstrain-153_jpg.rf.ab54108710ba9006c6cfb037ec43b1b5.jpg')\n",
    "image = image.resize((224,224))\n",
    "image = np.array(image, dtype=np.uint8)\n",
    "image = np.moveaxis(image, source=-1, destination=0) # channels first for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this can be converted to json\n",
    "inputs = feature_extractor(image)\n",
    "pixel_values = inputs[\"pixel_values\"]\n",
    "pixel_values = np.array(pixel_values)\n",
    "pixel_values = pixel_values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#still seem to have issues with using AWS endpoints for HuggingFace image classification. We will use Heroku instead\n",
    "rt_predictor.predict({\"inputs\": values })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete endpoint to not incure costs\n",
    "rt_predictor.delete_model()\n",
    "rt_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
